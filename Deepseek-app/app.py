import streamlit as st
import google.generativeai as genai
import os

# C·∫•u h√¨nh Google Generative AI v·ªõi API key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY_NEW')
genai.configure(api_key=GOOGLE_API_KEY)

st.title("üê≥ Chat Gemini üê≥")
st.subheader("ü§ñ Gemini Chatbot Prototype ü§ñ", divider="blue")

# Sidebar UI: c·∫•u h√¨nh tham s·ªë cho LLM
st.sidebar.markdown("## Parameters")
st.sidebar.divider()
model = st.sidebar.radio("Choose LLM:", ("gemini-1.5-flash", "gemini-1.5-pro"))
temp = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=1.0, step=0.25)
top_p = st.sidebar.slider("Top P:", min_value=0.0, max_value=1.0, value=0.94, step=0.01)
max_tokens = st.sidebar.slider("Maximum Tokens:", min_value=100, max_value=5000, value=2000, step=100)

# L∆∞u l·ªãch s·ª≠ chat trong session_state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if prompt := st.chat_input("Enter your message:"):
    try:
        # Th√™m prompt c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ chat
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # T·∫°o placeholder ƒë·ªÉ hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa Gemini
        with st.chat_message("assistant"):
            placeholder = st.empty()
        
        # X√¢y d·ª±ng ng·ªØ c·∫£nh h·ªôi tho·∫°i (th√™m message h·ªá th·ªëng ban ƒë·∫ßu)
        messages = [{"role": "system", "content": "You're a helpful assistant"}] + st.session_state.chat_history
        conversation_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])
        
        # C·∫•u h√¨nh tham s·ªë t·∫°o n·ªôi dung cho Gemini
        generation_config = {
            "temperature": temp,
            "top_p": top_p,
            "max_output_tokens": max_tokens,
            "response_mime_type": "text/plain",
        }
        
        # T·∫°o instance model v√† g·ªçi API ƒë·ªÉ t·∫°o n·ªôi dung
        model_instance = genai.GenerativeModel(model_name=model, generation_config=generation_config)
        response = model_instance.generate_content([conversation_text])
        full_response = response.text
        
        # Hi·ªÉn th·ªã ph·∫£n h·ªìi t·ª´ Gemini
        placeholder.write(full_response)
        
        # L∆∞u l·∫°i ph·∫£n h·ªìi c·ªßa assistant v√†o l·ªãch s·ª≠ chat
        st.session_state.chat_history.append({"role": "assistant", "content": full_response})
        
    except Exception as e:
        st.error(f"Error: {e}")
